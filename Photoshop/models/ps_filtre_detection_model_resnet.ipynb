{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nassim\\AppData\\Local\\Temp\\ipykernel_14256\\1160388593.py:8: DeprecationWarning: Please use `loadmat` from the `scipy.io.matlab` namespace, the `scipy.io.matlab.mio` namespace is deprecated.\n",
      "  from scipy.io.matlab.mio import loadmat, savemat\n",
      "C:\\Users\\Nassim\\AppData\\Local\\Temp\\ipykernel_14256\\1160388593.py:8: DeprecationWarning: Please use `savemat` from the `scipy.io.matlab` namespace, the `scipy.io.matlab.mio` namespace is deprecated.\n",
      "  from scipy.io.matlab.mio import loadmat, savemat\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io.matlab.mio import loadmat, savemat\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as nnf\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "num_features = model.fc.in_features\n",
    "num_classes = 8\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 1000),  # New layer with 1000 outputs (matches pre-trained model)\n",
    "    nn.ReLU(),                       # Activation function (you can use others if needed)\n",
    "    nn.Linear(1000, num_classes)     # Final layer with 8 outputs for your classification task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining RESNET on player data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pair_img = '../data/photoshoptest'\n",
    "dataset = datasets.ImageFolder(root=path_pair_img, transform=preprocess)\n",
    "\n",
    "batch_size = 5\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[1;32m----> 2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.945551  [    5/ 6576]\n",
      "loss: 0.984768  [  505/ 6576]\n",
      "loss: 0.999304  [ 1005/ 6576]\n",
      "loss: 0.952106  [ 1505/ 6576]\n",
      "loss: 1.335849  [ 2005/ 6576]\n",
      "loss: 0.821348  [ 2505/ 6576]\n",
      "loss: 1.057048  [ 3005/ 6576]\n",
      "loss: 1.318319  [ 3505/ 6576]\n",
      "loss: 1.251393  [ 4005/ 6576]\n",
      "loss: 1.014067  [ 4505/ 6576]\n",
      "loss: 1.214785  [ 5005/ 6576]\n",
      "loss: 0.857582  [ 5505/ 6576]\n",
      "loss: 1.004859  [ 6005/ 6576]\n",
      "loss: 0.619097  [ 6505/ 6576]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.213788  [    5/ 6576]\n",
      "loss: 0.997163  [  505/ 6576]\n",
      "loss: 1.314827  [ 1005/ 6576]\n",
      "loss: 0.931822  [ 1505/ 6576]\n",
      "loss: 0.688763  [ 2005/ 6576]\n",
      "loss: 0.623131  [ 2505/ 6576]\n",
      "loss: 0.699024  [ 3005/ 6576]\n",
      "loss: 0.651918  [ 3505/ 6576]\n",
      "loss: 0.249230  [ 4005/ 6576]\n",
      "loss: 0.698804  [ 4505/ 6576]\n",
      "loss: 1.228164  [ 5005/ 6576]\n",
      "loss: 0.682262  [ 5505/ 6576]\n",
      "loss: 0.492340  [ 6005/ 6576]\n",
      "loss: 1.344578  [ 6505/ 6576]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.748557  [    5/ 6576]\n",
      "loss: 0.688876  [  505/ 6576]\n",
      "loss: 0.099075  [ 1005/ 6576]\n",
      "loss: 0.505620  [ 1505/ 6576]\n",
      "loss: 0.953352  [ 2005/ 6576]\n",
      "loss: 0.526163  [ 2505/ 6576]\n",
      "loss: 1.232389  [ 3005/ 6576]\n",
      "loss: 0.583652  [ 3505/ 6576]\n",
      "loss: 0.937530  [ 4005/ 6576]\n",
      "loss: 1.591344  [ 4505/ 6576]\n",
      "loss: 0.574079  [ 5005/ 6576]\n",
      "loss: 0.001156  [ 5505/ 6576]\n",
      "loss: 1.318717  [ 6005/ 6576]\n",
      "loss: 0.536530  [ 6505/ 6576]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.941406  [    5/ 6576]\n",
      "loss: 0.620426  [  505/ 6576]\n",
      "loss: 0.201274  [ 1005/ 6576]\n",
      "loss: 0.860929  [ 1505/ 6576]\n",
      "loss: 0.060920  [ 2005/ 6576]\n",
      "loss: 0.667425  [ 2505/ 6576]\n",
      "loss: 2.149152  [ 3005/ 6576]\n",
      "loss: 0.989368  [ 3505/ 6576]\n",
      "loss: 0.516020  [ 4005/ 6576]\n",
      "loss: 1.529627  [ 4505/ 6576]\n",
      "loss: 0.263342  [ 5005/ 6576]\n",
      "loss: 0.424661  [ 5505/ 6576]\n",
      "loss: 0.419596  [ 6005/ 6576]\n",
      "loss: 0.759206  [ 6505/ 6576]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.386239  [    5/ 6576]\n",
      "loss: 0.769241  [  505/ 6576]\n",
      "loss: 0.111147  [ 1005/ 6576]\n",
      "loss: 0.469041  [ 1505/ 6576]\n",
      "loss: 0.694946  [ 2005/ 6576]\n",
      "loss: 0.015449  [ 2505/ 6576]\n",
      "loss: 0.904084  [ 3005/ 6576]\n",
      "loss: 0.439685  [ 3505/ 6576]\n",
      "loss: 0.364087  [ 4005/ 6576]\n",
      "loss: 0.481806  [ 4505/ 6576]\n",
      "loss: 0.544587  [ 5005/ 6576]\n",
      "loss: 0.419042  [ 5505/ 6576]\n",
      "loss: 1.281640  [ 6005/ 6576]\n",
      "loss: 0.299975  [ 6505/ 6576]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.297659  [    5/ 6576]\n",
      "loss: 0.429005  [  505/ 6576]\n",
      "loss: 0.213874  [ 1005/ 6576]\n",
      "loss: 0.629778  [ 1505/ 6576]\n",
      "loss: 0.618011  [ 2005/ 6576]\n",
      "loss: 0.394041  [ 2505/ 6576]\n",
      "loss: 0.496431  [ 3005/ 6576]\n",
      "loss: 0.607342  [ 3505/ 6576]\n",
      "loss: 0.146712  [ 4005/ 6576]\n",
      "loss: 1.313862  [ 4505/ 6576]\n",
      "loss: 0.197125  [ 5005/ 6576]\n",
      "loss: 0.943214  [ 5505/ 6576]\n",
      "loss: 0.367240  [ 6005/ 6576]\n",
      "loss: 0.397760  [ 6505/ 6576]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.614609  [    5/ 6576]\n",
      "loss: 0.186069  [  505/ 6576]\n",
      "loss: 0.208785  [ 1005/ 6576]\n",
      "loss: 0.080241  [ 1505/ 6576]\n",
      "loss: 0.748273  [ 2005/ 6576]\n",
      "loss: 0.510752  [ 2505/ 6576]\n",
      "loss: 0.465106  [ 3005/ 6576]\n",
      "loss: 0.611595  [ 3505/ 6576]\n",
      "loss: 0.417206  [ 4005/ 6576]\n",
      "loss: 0.054417  [ 4505/ 6576]\n",
      "loss: 0.391782  [ 5005/ 6576]\n",
      "loss: 3.094499  [ 5505/ 6576]\n",
      "loss: 0.510978  [ 6005/ 6576]\n",
      "loss: 0.151209  [ 6505/ 6576]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.542068  [    5/ 6576]\n",
      "loss: 0.239788  [  505/ 6576]\n",
      "loss: 0.139491  [ 1005/ 6576]\n",
      "loss: 0.131968  [ 1505/ 6576]\n",
      "loss: 0.483552  [ 2005/ 6576]\n",
      "loss: 0.453933  [ 2505/ 6576]\n",
      "loss: 0.077574  [ 3005/ 6576]\n",
      "loss: 0.258111  [ 3505/ 6576]\n",
      "loss: 0.490666  [ 4005/ 6576]\n",
      "loss: 0.018721  [ 4505/ 6576]\n",
      "loss: 0.332693  [ 5005/ 6576]\n",
      "loss: 0.855935  [ 5505/ 6576]\n",
      "loss: 0.119210  [ 6005/ 6576]\n",
      "loss: 0.234631  [ 6505/ 6576]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.238601  [    5/ 6576]\n",
      "loss: 0.091765  [  505/ 6576]\n",
      "loss: 0.153841  [ 1005/ 6576]\n",
      "loss: 0.899404  [ 1505/ 6576]\n",
      "loss: 0.216413  [ 2005/ 6576]\n",
      "loss: 0.350693  [ 2505/ 6576]\n",
      "loss: 0.005705  [ 3005/ 6576]\n",
      "loss: 0.490483  [ 3505/ 6576]\n",
      "loss: 0.184834  [ 4005/ 6576]\n",
      "loss: 0.132113  [ 4505/ 6576]\n",
      "loss: 0.214978  [ 5005/ 6576]\n",
      "loss: 0.106866  [ 5505/ 6576]\n",
      "loss: 0.086322  [ 6005/ 6576]\n",
      "loss: 0.106750  [ 6505/ 6576]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.091640  [    5/ 6576]\n",
      "loss: 0.236324  [  505/ 6576]\n",
      "loss: 0.289819  [ 1005/ 6576]\n",
      "loss: 0.808386  [ 1505/ 6576]\n",
      "loss: 0.432213  [ 2005/ 6576]\n",
      "loss: 0.188405  [ 2505/ 6576]\n",
      "loss: 0.118297  [ 3005/ 6576]\n",
      "loss: 0.097531  [ 3505/ 6576]\n",
      "loss: 0.090235  [ 4005/ 6576]\n",
      "loss: 0.007774  [ 4505/ 6576]\n",
      "loss: 0.632702  [ 5005/ 6576]\n",
      "loss: 0.452763  [ 5505/ 6576]\n",
      "loss: 0.123989  [ 6005/ 6576]\n",
      "loss: 0.514051  [ 6505/ 6576]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.265540  [    5/ 6576]\n",
      "loss: 0.349681  [  505/ 6576]\n",
      "loss: 0.000135  [ 1005/ 6576]\n",
      "loss: 0.024899  [ 1505/ 6576]\n",
      "loss: 0.003468  [ 2005/ 6576]\n",
      "loss: 0.119561  [ 2505/ 6576]\n",
      "loss: 0.581670  [ 3005/ 6576]\n",
      "loss: 0.019570  [ 3505/ 6576]\n",
      "loss: 0.621427  [ 4005/ 6576]\n",
      "loss: 0.129357  [ 4505/ 6576]\n",
      "loss: 0.588565  [ 5005/ 6576]\n",
      "loss: 0.201724  [ 5505/ 6576]\n",
      "loss: 0.052909  [ 6005/ 6576]\n",
      "loss: 0.381407  [ 6505/ 6576]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.148178  [    5/ 6576]\n",
      "loss: 0.959016  [  505/ 6576]\n",
      "loss: 0.039899  [ 1005/ 6576]\n",
      "loss: 0.626672  [ 1505/ 6576]\n",
      "loss: 0.739485  [ 2005/ 6576]\n",
      "loss: 0.317114  [ 2505/ 6576]\n",
      "loss: 0.043871  [ 3005/ 6576]\n",
      "loss: 0.366873  [ 3505/ 6576]\n",
      "loss: 0.370144  [ 4005/ 6576]\n",
      "loss: 0.303860  [ 4505/ 6576]\n",
      "loss: 1.149856  [ 5005/ 6576]\n",
      "loss: 0.015573  [ 5505/ 6576]\n",
      "loss: 1.574792  [ 6005/ 6576]\n",
      "loss: 0.001225  [ 6505/ 6576]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.132230  [    5/ 6576]\n",
      "loss: 0.073879  [  505/ 6576]\n",
      "loss: 0.217173  [ 1005/ 6576]\n",
      "loss: 0.001318  [ 1505/ 6576]\n",
      "loss: 0.353637  [ 2005/ 6576]\n",
      "loss: 1.554962  [ 2505/ 6576]\n",
      "loss: 0.496146  [ 3005/ 6576]\n",
      "loss: 0.189235  [ 3505/ 6576]\n",
      "loss: 0.001952  [ 4005/ 6576]\n",
      "loss: 0.634932  [ 4505/ 6576]\n",
      "loss: 0.544159  [ 5005/ 6576]\n",
      "loss: 0.000041  [ 5505/ 6576]\n",
      "loss: 0.001850  [ 6005/ 6576]\n",
      "loss: 0.128876  [ 6505/ 6576]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.077829  [    5/ 6576]\n",
      "loss: 0.002326  [  505/ 6576]\n",
      "loss: 0.175974  [ 1005/ 6576]\n",
      "loss: 0.113562  [ 1505/ 6576]\n",
      "loss: 0.269398  [ 2005/ 6576]\n",
      "loss: 0.006315  [ 2505/ 6576]\n",
      "loss: 0.101773  [ 3005/ 6576]\n",
      "loss: 0.255258  [ 3505/ 6576]\n",
      "loss: 0.142243  [ 4005/ 6576]\n",
      "loss: 0.024313  [ 4505/ 6576]\n",
      "loss: 0.574570  [ 5005/ 6576]\n",
      "loss: 0.106491  [ 5505/ 6576]\n",
      "loss: 0.554579  [ 6005/ 6576]\n",
      "loss: 0.911729  [ 6505/ 6576]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.003361  [    5/ 6576]\n",
      "loss: 0.002783  [  505/ 6576]\n",
      "loss: 0.146854  [ 1005/ 6576]\n",
      "loss: 0.584672  [ 1505/ 6576]\n",
      "loss: 0.096148  [ 2005/ 6576]\n",
      "loss: 0.232128  [ 2505/ 6576]\n",
      "loss: 0.300057  [ 3005/ 6576]\n",
      "loss: 0.071074  [ 3505/ 6576]\n",
      "loss: 0.768879  [ 4005/ 6576]\n",
      "loss: 0.516209  [ 4505/ 6576]\n",
      "loss: 0.274395  [ 5005/ 6576]\n",
      "loss: 0.225611  [ 5505/ 6576]\n",
      "loss: 0.525422  [ 6005/ 6576]\n",
      "loss: 0.001109  [ 6505/ 6576]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.006288  [    5/ 6576]\n",
      "loss: 0.093721  [  505/ 6576]\n",
      "loss: 0.014057  [ 1005/ 6576]\n",
      "loss: 0.182389  [ 1505/ 6576]\n",
      "loss: 0.124094  [ 2005/ 6576]\n",
      "loss: 0.400656  [ 2505/ 6576]\n",
      "loss: 0.065718  [ 3005/ 6576]\n",
      "loss: 0.020870  [ 3505/ 6576]\n",
      "loss: 0.000129  [ 4005/ 6576]\n",
      "loss: 0.009755  [ 4505/ 6576]\n",
      "loss: 0.078817  [ 5005/ 6576]\n",
      "loss: 0.430908  [ 5505/ 6576]\n",
      "loss: 0.462812  [ 6005/ 6576]\n",
      "loss: 0.917510  [ 6505/ 6576]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.011386  [    5/ 6576]\n",
      "loss: 0.487600  [  505/ 6576]\n",
      "loss: 0.102253  [ 1005/ 6576]\n",
      "loss: 0.291468  [ 1505/ 6576]\n",
      "loss: 0.038678  [ 2005/ 6576]\n",
      "loss: 0.003939  [ 2505/ 6576]\n",
      "loss: 0.239005  [ 3005/ 6576]\n",
      "loss: 0.382138  [ 3505/ 6576]\n",
      "loss: 0.422885  [ 4005/ 6576]\n",
      "loss: 0.000305  [ 4505/ 6576]\n",
      "loss: 0.530835  [ 5005/ 6576]\n",
      "loss: 0.353656  [ 5505/ 6576]\n",
      "loss: 0.879242  [ 6005/ 6576]\n",
      "loss: 0.168965  [ 6505/ 6576]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.091869  [    5/ 6576]\n",
      "loss: 0.006573  [  505/ 6576]\n",
      "loss: 0.027717  [ 1005/ 6576]\n",
      "loss: 0.400591  [ 1505/ 6576]\n",
      "loss: 0.028771  [ 2005/ 6576]\n",
      "loss: 0.037679  [ 2505/ 6576]\n",
      "loss: 0.018468  [ 3005/ 6576]\n",
      "loss: 0.007550  [ 3505/ 6576]\n",
      "loss: 0.002827  [ 4005/ 6576]\n",
      "loss: 0.003606  [ 4505/ 6576]\n",
      "loss: 0.468866  [ 5005/ 6576]\n",
      "loss: 0.026152  [ 5505/ 6576]\n",
      "loss: 0.068062  [ 6005/ 6576]\n",
      "loss: 0.143940  [ 6505/ 6576]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.003119  [    5/ 6576]\n",
      "loss: 0.380947  [  505/ 6576]\n",
      "loss: 0.037772  [ 1005/ 6576]\n",
      "loss: 0.039889  [ 1505/ 6576]\n",
      "loss: 0.024208  [ 2005/ 6576]\n",
      "loss: 0.039339  [ 2505/ 6576]\n",
      "loss: 0.273635  [ 3005/ 6576]\n",
      "loss: 0.017271  [ 3505/ 6576]\n",
      "loss: 0.063868  [ 4005/ 6576]\n",
      "loss: 0.000793  [ 4505/ 6576]\n",
      "loss: 0.085440  [ 5005/ 6576]\n",
      "loss: 0.337989  [ 5505/ 6576]\n",
      "loss: 0.000278  [ 6005/ 6576]\n",
      "loss: 0.137918  [ 6505/ 6576]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.579178  [    5/ 6576]\n",
      "loss: 0.520041  [  505/ 6576]\n",
      "loss: 0.947029  [ 1005/ 6576]\n",
      "loss: 0.176370  [ 1505/ 6576]\n",
      "loss: 0.005755  [ 2005/ 6576]\n",
      "loss: 0.084163  [ 2505/ 6576]\n",
      "loss: 0.044147  [ 3005/ 6576]\n",
      "loss: 0.017437  [ 3505/ 6576]\n",
      "loss: 0.203268  [ 4005/ 6576]\n",
      "loss: 0.418798  [ 4505/ 6576]\n",
      "loss: 0.257052  [ 5005/ 6576]\n",
      "loss: 0.096548  [ 5505/ 6576]\n",
      "loss: 0.131094  [ 6005/ 6576]\n",
      "loss: 0.074231  [ 6505/ 6576]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "torch.cuda.empty_cache()\n",
    "for i in range(1):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model_resnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing training on handmade dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "model_resnet_retrain = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "num_features = model_resnet_retrain.fc.in_features\n",
    "num_classes = 8\n",
    "\n",
    "model_resnet_retrain.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 1000),  # New layer with 1000 outputs (matches pre-trained model)\n",
    "    nn.ReLU(),                       \n",
    "    nn.Linear(1000, num_classes)    # Final layer with 8 outputs for your classification task\n",
    ")\n",
    "\n",
    "model_resnet_retrain = model_resnet_retrain.cuda()\n",
    "\n",
    "model_resnet_retrain.load_state_dict(torch.load(\"./model_resnet\"))\n",
    "\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pair_img = '../data/photoshoptest_handmade'\n",
    "dataset = datasets.ImageFolder(root=path_pair_img, transform=preprocess)\n",
    "\n",
    "batch_size = 5\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet_retrain.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.026977  [    5/  121]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.621275  [    5/  121]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.424157  [    5/  121]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.255032  [    5/  121]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.235204  [    5/  121]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.168232  [    5/  121]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.028000  [    5/  121]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.013707  [    5/  121]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.029799  [    5/  121]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.001812  [    5/  121]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.794239  [    5/  121]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.001180  [    5/  121]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.050332  [    5/  121]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.047060  [    5/  121]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.038990  [    5/  121]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.022972  [    5/  121]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.048150  [    5/  121]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.033397  [    5/  121]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.012206  [    5/  121]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000117  [    5/  121]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "torch.cuda.empty_cache()\n",
    "for i in range(1):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model_resnet_retrain, loss_fn, optimizer)\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_resnet_retrain.state_dict(), \"./model_resnet_retrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
